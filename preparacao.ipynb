{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.impute import SimpleImputer # tratamento de valores ausentes\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer # definir tratamento para cada lista de variáveis\n",
    "from sklearn.pipeline import Pipeline # definir sequência de cálculos do algoritmo de aprendizagem\n",
    "\n",
    "#biliotecas do usuario\n",
    "from transformadores import *\n",
    "from utils import remover_outlier, buscar_outlier\n",
    "\n",
    "#bibliotecas de visualização\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Omitir warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando os dados\n",
    "dados = pd.read_csv('dados.csv',\n",
    "                   sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Número de linhas: {dados.shape[0]}')\n",
    "print(f'Número de colunas: {dados.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Primeiro, vamos definir qual é o problema que iremos solucionar.</p>\n",
    "<p>Seguindo a ordem sugerida no escopo do desafio, temos</p>\n",
    "<ol>\n",
    "    <li>Estimar o faturamento</li>\n",
    "    <li>Classificar o potencial</li>\n",
    "    <li>Clusterizar por perfil e renda</li>\n",
    "<ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Analisando os dados disponíveis, temos que a variável potencial pode ser retirada. Esse pensamento se justifica, pois em um ambiente produtivo, teríamos um modelo estimando o faturamento e em seguida estimaríamos o potencial.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dados utilizados para modelarmos o faturamento\n",
    "dados_fat = dados.drop('potencial',\n",
    "                       axis = 1)\\\n",
    "                .copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_fat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_fat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Número de linhas: {dados_fat.shape[0]}')\n",
    "print(f'Número de colunas: {dados_fat.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Como nosso problema consistirá em prever o faturamento por bairro em SP, trataremos os dados referentes ao mesmo como dados <i>out of sample</i>, ou seja, os dados de produção.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dados_fat[dados_fat.estado == 'RJ'].reset_index().drop('index',axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Número de linhas: {df.shape[0]}')\n",
    "print(f'Número de colunas: {df.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rendaMedia = df.rendaMedia.astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Temos então 160 observações para analisarmos, antes de inicarmos o processo de modelagem.</p>\n",
    "<p>Vamos separar as variáveis que iremos utilizar. Nesse primeiro momento, podemos retirar as variáveis de código, nome, cidade e estado.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis Numéricas\n",
    "vnum = [x for x in df.columns if x not in ['codigo', 'nome', 'cidade','estado','faturamento']]\n",
    "# Variável target\n",
    "vtgt = ['faturamento']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Fazendo uma análise nos tipos de dados de cada variável, temos que rendaMedia está como <i>object</i>. Antes que seguir a análise, vamos tranformá-la em <i>float</i>.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Podemos começar fazendo uma análise descritiva dos dados, buscando entender o comportamento e distribuição dos mesmos.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[vnum].isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[vnum].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Observamos que temos 6 dados nulos na variável rendaMedia. Além disso, vemos uma distribuição muito esparsa dos dados, pois o valor mínimo é 645 e o máximo 63887.</p>\n",
    "</p>Primeiro, vamos tratar os dados nulos. Existem várias forma de se trata um dado nulo, tais como:</p>\n",
    "<ol>\n",
    "    <li>Substituir por alguma estatística descritiva (Ex: Média, Mediana, Moda)</li>\n",
    "    <li>Deletar as observações</li>\n",
    "    <li>Estimar os valores utilizando um modelo.</li>\n",
    "<ol>\n",
    "    \n",
    "<p>Por simplicidade e por temos poucos dados nulos, vamos utilizar a técnica de substituir os dados pela mediana. Essa decisão vem através da análise do boxplot abaixo.</p>\n",
    "    <p>Podemos observar que os dados estão muito concentrados em valores próximos ao mínimo da observação da rendaMedia e existem valores muito discrepantes, por isso usar a estrátegia da median conseguiríamos trazer esse valores da rendaMedia para uma escala mais real.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Antes de fazermos o preenchimento de dados nulos, vamos retirar os <i>outliers</i>, pois podemos causar distorção no resultado do modelo no futuro. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df.dropna().rendaMedia, data=df, orient='h', palette=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(7, 2, figsize = (20, 25), facecolor='white')  \n",
    "for axs, v in zip(axs.flatten(), vnum):\n",
    "    ax = sns.boxplot(x=v, data=df, orient='h', palette=\"Blues\", ax=axs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Vamos investigar quais observações estão gerando essa distorção nos dados. Esses valores devem ser ajustados, pois o uso de de outliers causa distorções no modelo que não queremos.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictt = {}\n",
    "for col in df[vnum].columns:\n",
    "    dictt[col] = buscar_outlier(df[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[key,len(value)] for key,value in dictt.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Quantidade de Outliers: {[(key,len(value)) for key,value in dictt.items()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método de imputação para variáveis numéricas -> substituir pela mediana\n",
    "imp_num = SimpleImputer(missing_values=np.nan, strategy='median', add_indicator=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformador_numerico = Pipeline(steps = [('imputer', imp_num),\n",
    "                                           ('nomes', NomeadorAtributos(colunas = vnum))], verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num  = transformador_numerico.fit_transform(df[vnum])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Como estamos trabalahndo com valores muito discrepantes, vamos seguir a técnica de normalização das <i>features</i>. Usaremos para isso a transformação Min-Max.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instanciando MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adicionando na pipeline \n",
    "transformador_numerico.steps.append(('normalizador', scaler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformador_numerico.fit(df[vnum])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = pd.DataFrame(transformador_numerico.fit_transform(df[vnum]), columns = vnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num.describe().T.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,20))\n",
    "sns.heatmap(df[vtgt+vnum].corr(), annot = True, cmap = 'magma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.concat([df_num, df[vtgt]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Aplicando o VIF para retirar colinearidade.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vif = df_new.copy()\n",
    "df_vif.drop('faturamento', axis = 1, inplace = True)\n",
    "df_vif['constante'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif['VIF Factor'] = [variance_inflation_factor(df_vif.values,i) for i in range(df_vif.shape[1])]\n",
    "vif['features'] = df_vif.columns\n",
    "vif.sort_values('VIF Factor', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Para tratarmos nosso dados que podem vir nulos, vamos criar um imputer para preenche-los com a mediana.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Como os dados têm uma discrepância em escala, vamos fazer uma normalização dos dados para deixá-los em um range de (0,1).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Ao analisarmos o <i>heatmap</i> podemos ver uma grande correlação entra as variáveis de população.\n",
    "Além disso, vemos que as variáveis de domicílios A1, A2, B1 junto com a rendaMedia são as variáveis que impactam positivamente o faturamento.</p>\n",
    "<p>Para contornamos o problema da multicolienaridade de uma forma mais simple vamos utilizar algoritmos de floresta, como RandomForest.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>O segundo passo é verificar se encontramos alguma colinearidade entre as variáveis.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Na célula abaixo será consolidado os diversos tratamentos aplicados a cada conjunto de variáveis.\n",
    "Para as variáveis numéricas a necessidade de imputação pela média nos valores ausentes e para as variáveis categóricas a criação de variáveis indicadoras.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
